# Example user configuration for model orchestrator
# Researchers can drop these configs to customize model selection

name: "Example Research Config"

# Define experiments for A/B testing
experiments:
  # Fast mode: race multiple fast models
  fast:
    strategy: race
    providers:
      - openai/gpt-4o-mini
      - anthropic/claude-3-haiku
      - local/llama-3
    timeout: 30000

  # Quality mode: use best models
  quality:
    strategy: first
    providers:
      - anthropic/claude-3.5-sonnet
      - openai/gpt-4o
    timeout: 60000
    maxCost: 0.10

  # Local first: prefer local models, fallback to cloud
  local_first:
    strategy: fallback
    providers:
      - local/llama-3.3
      - local/mistral-nemo
      - openrouter/google/gemini-2.0-flash
    timeout: 45000

  # Consensus mode: run multiple models and compare
  consensus:
    strategy: consensus
    providers:
      - anthropic/claude-3.5-sonnet
      - openai/gpt-4o
      - openrouter/google/gemini-2.0-flash
    timeout: 90000

# Default settings
defaults:
  experiment: fast
  maxConcurrent: 50
  timeout: 30000
  costLimit: 10.00  # USD per hour

# Enable performance tracking
performanceTracking: true