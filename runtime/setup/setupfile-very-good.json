{
  "nodes": [
    {
      "nodeId": "workflow-node-starter",
      "description": "Describe the data and identify the target company and location",
      "systemPrompt": "Describe the data and identify the target company and location for B2C certified sustainable companies in the specified region.",
      "modelName": "google/gemini-2.5-flash-lite",
      "mcpTools": [],
      "codeTools": [],
      "handOffs": [
        "location_data_extractor"
      ],
      "memory": {
        "B2C_B-Corp_focus": "search_strategy:Focus on B2C certified sustainable companies for specific company information:71",
        "target_location": "search_strategy:Target location for sustainable company searches:71",
        "company_type": "search_strategy:Focus on specific industry companies when searching for sustainable companies:71",
        "specific_company_focus": "search_strategy:Focus on finding physical store locations for a specific company:71",
        "B_Corp_industry": "search_strategy:Sustainable companies in specific industries can be further refined:71",
        "company_size": "search_strategy:Sustainable companies with specific employee counts are a relevant target size:70",
        "target_company_focus": "search_strategy:Focus on finding physical store locations for target company:70",
        "company_specialization": "search_strategy:When searching for sustainable companies, specify company specialization to refine results:60"
      }
    },
    {
      "nodeId": "location_data_extractor",
      "description": "Extract comprehensive physical store locations using Google Maps searches with immediate tavily web search backup for complete data collection",
      "systemPrompt": "You are the primary data collection agent for finding ALL target company store locations in the specified region. Execute this comprehensive search strategy: PHASE 1 - GOOGLE MAPS: Perform searches using searchGoogleMaps with various search terms for the target company. For each search, immediately store ALL results using locationDataManager.insertLocations(). PHASE 2 - WEB SEARCH BACKUP: If Google Maps returns fewer than 5 locations OR any searches return empty results, immediately use tavily to search for store locations using various search terms. Extract ALL store information from web results and store using locationDataManager.insertLocations(). PHASE 3 - VALIDATION: Use locationDataManager.getLocations() to verify at least 5-10 locations were collected with addresses. CRITICAL: Always proceed to handoff even with partial data - downstream nodes will enrich it. Your goal is maximum location discovery using both Google Maps and web search to ensure comprehensive coverage.",
      "modelName": "openai/gpt-4.1-mini",
      "mcpTools": [
        "tavily"
      ],
      "codeTools": [
        "searchGoogleMaps",
        "locationDataManager"
      ],
      "handOffs": [
        "web_search_coordinator"
      ],
      "memory": {}
    },
    {
      "nodeId": "data_consolidator",
      "description": "Parse and consolidate raw Google Maps search data into structured store information without web searches",
      "systemPrompt": "Parse and consolidate raw search results from Google Maps into structured store data. Extract store names, addresses, coordinates, phone numbers, opening hours, and other relevant information from the Google Maps data stored by the previous node. Use locationDataManager to retrieve the stored Google Maps results and clean/structure this data. Validate addresses and fill missing coordinates using verifyLocation tool when needed. Create a unified dataset of ALL store locations for the target company found in Google Maps searches. Handle incomplete data by marking missing fields as null rather than attempting web searches. Focus on maximizing the value of existing Google Maps data. After consolidation, hand off to web_enrichment_agent for any additional data enrichment.",
      "modelName": "openai/gpt-4.1-mini",
      "mcpTools": [],
      "codeTools": [
        "locationDataManager",
        "verifyLocation"
      ],
      "handOffs": [
        "fallback_data_enricher"
      ],
      "memory": {
        "data_consolidation": "workflow:Consolidating data from Google Maps searches is crucial for complete and accurate store information:14",
        "location_validation": "workflow:Validating and cleaning location data, including coordinates, is essential for accuracy:14",
        "coordinates_requirement": "workflow:All store locations must include latitude and longitude coordinates in the final output:12",
        "error_handling": "workflow:Ensure data is correctly parsed and structured before submitting requests to avoid errors:35",
        "data_formatting": "workflow:Ensuring data adheres to the expected format is crucial for successful processing:29",
        "regional_focus": "workflow:Prioritize locations within the target region for the company:14",
        "b2c_focus": "workflow:Focus on B2C stores when identifying target company locations:13",
        "google_maps_focus": "workflow:Focus on consolidating Google Maps data for efficient processing:13",
        "incomplete_data_handling": "workflow:Handle incomplete data by marking missing fields as null:5"
      }
    },
    {
      "nodeId": "json_structure_validator",
      "description": "Validate and structure data into required JSON schema format",
      "systemPrompt": "Transform the consolidated store location data into the exact JSON schema format required by the ground truth. Ensure each location has properly structured fields: 'name', 'address', 'city', 'postcode', 'coordinates' (as object with 'latitude' and 'longitude'), 'phone', 'opening_hours', 'website', 'owner_imgs' (as array), and 'images' (as array). Validate that all required fields are present and properly formatted. If any data is missing, mark it as null or empty array as appropriate. Ensure coordinates are properly extracted as separate latitude and longitude values, not as combined strings. If Google Maps data was incomplete or missing, trigger web_search_fallback to supplement data; otherwise, proceed to result_formatter.",
      "modelName": "openai/gpt-4.1-mini",
      "mcpTools": [],
      "codeTools": [
        "locationDataManager"
      ],
      "handOffs": [
        "web_search_fallback",
        "result_formatter"
      ],
      "memory": {
        "data_transformation_error": "tool_limitation:Data transformation cannot proceed without a valid response format and data structure:20",
        "json_schema_formatting": "instruction:Ensure data is structured according to the correct JSON schema, paying close attention to required fields and formats, and handle any missing data appropriately:29",
        "coordinate_extraction": "instruction:Ensure coordinates are extracted as separate latitude and longitude values, not as combined strings:22",
        "web_search_fallback": "instruction:Use web search to supplement incomplete or missing Google Maps data:23",
        "data_validation": "instruction:Validate the data structure before processing to ensure it is in a usable format:17",
        "b2c_filter": "instruction:Filter data to include only B2C businesses with physical stores:15",
        "hq_location_check": "instruction:Skip companies if their HQ is not in the target region and the countries of operation field is empty:14",
        "incomplete_data_handling": "instruction:Request complete data if the initial input is truncated or insufficient for processing:12",
        "error_debugging": "instruction:When an error occurs, request the tool name, input, output, and expected format for debugging:10",
        "invalid_response_handling": "instruction:If a previous step results in an invalid response format, request the tool name, input, output, and expected format for debugging:9",
        "debugging_information_request": "instruction:Request the tool name, input, output, and expected format when debugging invalid responses:7",
        "data_request_before_transformation": "instruction:Always request the data before attempting to transform it into the required JSON schema:2",
        "data_enrichment_trigger": "instruction:Trigger web search to supplement missing data like coordinates and opening hours:1",
        "data_transformation_halted": "tool_limitation:Data transformation should be paused if data enrichment is blocked due to tool limitations:1",
        "tool_response_debugging": "instruction:Request tool details (name, input, output, expected format) when a response indicates failure or empty data:3",
        "location_data_retrieval": "instruction:Use the locationDataManager tool with the getLocations operation to retrieve initial location data:1",
        "data_format_request": "instruction:Request the data in a usable format before attempting transformation:1",
        "tool_execution_required": "instruction:Ensure a tool is executed to retrieve the data before attempting transformation:1"
      }
    },
    {
      "nodeId": "web_search_fallback",
      "description": "Fallback web search for store locations when Google Maps fails or data is incomplete",
      "systemPrompt": "When Google Maps search fails or returns incomplete results, perform comprehensive web searches for target company store locations in the specified region. Search for official website, store locators, business directories, and social media to extract store addresses, contact information, and opening hours. Focus on finding multiple store locations with as much detail as possible. Store the gathered data using locationDataManager and hand off to data_consolidator for parsing and validation.",
      "modelName": "openai/gpt-4.1-mini",
      "mcpTools": [
        "firecrawl"
      ],
      "codeTools": [
        "locationDataManager"
      ],
      "handOffs": [
        "data_consolidator"
      ],
      "memory": {
        "google_maps_failure": "tool_limitation:When Google Maps fails for store locations, use comprehensive web searches including official websites, directories, and social media:4",
        "web_search_store_locations": "strategy:When Google Maps fails for store locations, prioritize web searches for official websites, store locators, business directories, and social media to extract store addresses, contact information, and opening hours:1"
      }
    },
    {
      "nodeId": "result_formatter",
      "description": "Comprehensive final data retrieval, enrichment, and formatting into structured JSON output",
      "systemPrompt": "Execute these steps to produce complete final JSON output: 1) Use locationDataManager.getLocations() to retrieve all stored location data for the target company. 2) If no data exists or data is incomplete, use tavily to comprehensively search for: '... store locations Netherlands', '... winkel adressen', '... shops Netherlands', '... Van Goeden Huize stores'. 3) For each location found, search for additional details: '[store address] opening hours phone', '[store name] contact information', '... [city] store details'. 4) Use verifyLocation to get precise coordinates for any addresses missing lat/lng. 5) Format each location into exact JSON schema: {'name': string, 'address': string, 'city': string, 'postcode': string, 'coordinates': {'latitude': number, 'longitude': number}, 'phone': string|null, 'opening_hours': string|null, 'website': string|null, 'owner_imgs': [], 'images': []}. 6) Ensure minimum 3-5 complete store locations with all available fields populated. 7) Use expectedOutputHandler to validate and return the complete JSON array. Return actual structured JSON data, not explanations or summaries.",
      "modelName": "openai/gpt-4.1-mini",
      "mcpTools": [
        "tavily"
      ],
      "codeTools": [
        "locationDataManager",
        "verifyLocation",
        "expectedOutputHandler"
      ],
      "handOffs": [
        "end"
      ],
      "memory": {}
    },
    {
      "nodeId": "web_enrichment_agent",
      "description": "Systematically enrich location data by searching for missing information across multiple web sources and ensuring complete data validation",
      "systemPrompt": "You are responsible for enriching incomplete location data for the target company stores. For each location retrieved from locationDataManager: 1) Identify missing fields (phone, website, opening_hours, owner_imgs, images, coordinates). 2) Use tavily to search for the official target company website and extract store-specific details. 3) Search for each store address + 'opening hours' + 'contact' to find missing phone numbers and hours. 4) For locations missing coordinates, use verifyLocation to geocode the addresses and obtain precise latitude/longitude. 5) Look for social media pages and business listings for additional store locations not yet found. 6) Search for '... store images' and '... owner photos' to populate image arrays with actual URLs. 7) For any completely new store locations discovered, extract full details and add them. 8) Use locationDataManager to update existing records and insert new locations with complete data. 9) Use expectedOutputHandler to validate that all locations have complete required fields before handoff. 10) Ensure you've searched comprehensively - the goal is to find 10+ store locations with complete data including coordinates, images, and contact details. Focus on systematic data enrichment and validation to ensure 100% data completeness.",
      "modelName": "openai/gpt-4.1-mini",
      "mcpTools": [
        "tavily"
      ],
      "codeTools": [
        "locationDataManager",
        "verifyLocation",
        "expectedOutputHandler"
      ],
      "handOffs": [
        "json_structure_validator"
      ],
      "memory": {
        "target_company_enrichment": "task_strategy:Enriching location data involves identifying missing fields, using Tavily to find official websites and store details, searching for addresses with 'opening hours' and 'contact' for phone numbers and hours, looking for social media and business listings, and searching for store and owner images.:6",
        "Comprehensive Search": "task_strategy:The goal is to find 10+ store locations with complete data through systematic data enrichment.:6",
        "Tavily Usage": "tool_usage:Tavily is useful for finding official websites and store details.:6",
        "Error Handling": "task_strategy:The process should continue despite encountering errors.:7",
        "Coordinate_Validation": "task_strategy:Use verifyLocation to ensure all locations have accurate latitude/longitude coordinates.:6",
        "Data_Completeness": "task_strategy:Use expectedOutputHandler to validate complete data before handoff to ensure all required fields are populated.:6",
        "Insufficient Information": "task_blocker:The agent requires initial location data to start the enrichment process.:14",
        "Output_Validation": "task_strategy:Validate the output format for each tool and function to avoid 'Invalid response format' errors.:1"
      }
    },
    {
      "nodeId": "url_content_parser",
      "description": "Parse URLs from tavily search results to extract detailed store location information",
      "systemPrompt": "Parse and extract detailed store location information from URLs found in previous tavily search results. Use firecrawl to scrape content from official target company websites, store locator pages, and business directory listings. Extract store names, complete addresses, phone numbers, opening hours, coordinates, and image URLs. Focus on finding all missing store locations and enriching existing data with complete details. Store all extracted data using locationDataManager.insertLocations() and update existing records with locationDataManager.updateLocations(). Ensure each location has complete address, coordinates, contact information, and opening hours before proceeding to validation.",
      "modelName": "openai/gpt-4.1-mini",
      "mcpTools": [
        "firecrawl"
      ],
      "codeTools": [
        "locationDataManager",
        "verifyLocation"
      ],
      "handOffs": [
        "web_enrichment_agent"
      ],
      "memory": {}
    },
    {
      "nodeId": "search_result_parser",
      "description": "Parse and extract structured location data from tavily search results and Google Maps data",
      "systemPrompt": "Parse tavily search results and Google Maps data to extract comprehensive store location information. For each search result: 1) Extract business names, addresses, phone numbers, and URLs from tavily results. 2) Parse Google Maps data for coordinates, opening hours, and additional details. 3) Use firecrawl to scrape official websites and store locator pages found in search results. 4) Extract complete address information, breaking down into street address, city, and postcode components. 5) Use verifyLocation to geocode any addresses missing coordinates. 6) Structure all extracted data into consistent format with fields: name, address, city, postcode, coordinates, phone, opening_hours, website. 7) Store all parsed locations using locationDataManager.insertLocations(). Focus on maximizing data extraction from search results to ensure comprehensive location coverage.",
      "modelName": "openai/gpt-4.1-mini",
      "mcpTools": [
        "firecrawl"
      ],
      "codeTools": [
        "locationDataManager",
        "verifyLocation"
      ],
      "handOffs": [
        "data_consolidator"
      ],
      "memory": {
        "location_data_extraction_workflow": "methodology:Extract location data by combining search results, Google Maps, and website scraping for comprehensive coverage:1",
        "address_parsing": "methodology:Break down addresses into street, city, and postcode components for structured data:1",
        "coordinate_verification": "methodology:Use geocoding to obtain coordinates for addresses when missing:1",
        "data_structuring": "methodology:Structure extracted data into a consistent format with name, address, city, postcode, coordinates, phone, opening_hours, and website fields:1"
      }
    },
    {
      "nodeId": "web_search_coordinator",
      "description": "Execute comprehensive web searches for the target company store locations when Google Maps data is insufficient",
      "systemPrompt": "Execute comprehensive web searches for the target company store locations in the target region when Google Maps data is insufficient. Use tavily to search: '... store locations Netherlands', '... winkel adressen Nederland', '... chocolate shops Netherlands', '... Van Goeden Huize stores', '... official website store locator'. Extract store names, addresses, phone numbers, opening hours, and website URLs from search results. Store all discovered locations using locationDataManager.insertLocations(). Focus on finding official websites and store locator pages that contain comprehensive location data. Ensure at least 5-10 store locations are collected before proceeding to parsing.",
      "modelName": "openai/gpt-4.1-mini",
      "mcpTools": [
        "tavily"
      ],
      "codeTools": [
        "locationDataManager"
      ],
      "handOffs": [
        "search_result_parser"
      ],
      "memory": {}
    },
    {
      "nodeId": "fallback_data_enricher",
      "description": "Enrich incomplete location data using available tools and strategies",
      "systemPrompt": "You are a data enrichment agent that maximizes data completeness using available tools: 1) Use locationDataManager.getLocations() to retrieve current data and identify missing fields (coordinates, phone, opening_hours, website). 2) For locations missing coordinates, use verifyLocation with the full address to obtain precise latitude/longitude. 3) Use searchGoogleMaps and tavily with alternative search terms to find additional details. 4) For missing phone numbers and hours, try searchGoogleMaps with specific queries for contact information or business hours. 5) Structure any new data found and use locationDataManager.updateLocations() to fill gaps. 6) If still missing critical data, use reasonable defaults: set opening_hours to 'Contact store for hours', phone to null, website to null, and ensure coordinates are always populated via verifyLocation. 7) Ensure minimum data quality: every location must have name, address, city, postcode, and coordinates before handoff. Focus on maximizing data completeness.",
      "modelName": "openai/gpt-4.1-mini",
      "mcpTools": [],
      "codeTools": [
        "locationDataManager",
        "verifyLocation",
        "searchGoogleMaps"
      ],
      "handOffs": [
        "url_content_parser"
      ],
      "memory": null
    }
  ],
  "entryNodeId": "workflow-node-starter",
  "contextFile": null
}